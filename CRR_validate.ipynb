{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set libraly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina' #Retina display\n",
    "plt.style.use('seaborn-deep') #Plot style\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Input\\\\\"\n",
    "input_data = \"Input\\\\data\\\\\"\n",
    "input_mapping = \"Input\\\\mapping\\\\\"\n",
    "output = \"Output\\\\\"\n",
    "backup_data = \"Input\\\\data\\\\backup_data\\\\\"\n",
    "output_graph = \"Output\\\\graph\\\\\"\n",
    "#os.mkdir(input)\n",
    "#os.mkdir(output)\n",
    "#os.mkdir(input_data)\n",
    "#os.mkdir(input_mapping)\n",
    "#os.mkdir(backup_data)\n",
    "#os.mkdir(output_graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawData:\n",
    "      def __init__(self, folder, folder2):\n",
    "    \n",
    "        self.folder = folder\n",
    "        self.file = glob.glob(folder+\"/*.csv\")[-1]\n",
    "        self.folder2 = folder2\n",
    "        self.file2 = glob.glob(folder+\"/*.xlsb\")[-1]\n",
    "\n",
    "    \n",
    "        print(f\"Start to read CSV file '{self.file[-26:]}' in folder '{self.folder}'\")\n",
    "        self.df = pd.read_csv(self.file,encoding='UTF-8' )\n",
    "        print(f\"Read CSV file '{self.file[-22:]}' done!\",\"\\n\")\n",
    "        \n",
    "      def remove_white_space(self):\n",
    "            print(\"Start remove_white_space function\")\n",
    "            for col in self.df.columns.tolist():\n",
    "              if self.df[col].dtypes == object:\n",
    "                self.df[col] = self.df[col].str.strip()\n",
    "              print(\"Remove_white_space done!\",\"\\n\")\n",
    "      def save_csv(self):\n",
    "              self.df.to_csv(input_data+\"test.csv\",encoding='TIS-620')\n",
    "              print(f\"save file {self.file[-22:]} done\" , \"\\n\")\n",
    "\n",
    "      #def mapping_data(self):\n",
    "       #       self.df_mapping = pd.read_excel(self.file2,encoding='UTF-8' )\n",
    "              \n",
    "    #self.file[-22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to read CSV file 'Input\\data\\CRR2563.csv' in folder 'Input\\data\\'\n",
      "Read CSV file 'Input\\data\\CRR2563.csv' done! \n",
      "\n",
      "Start remove_white_space function\n",
      "Remove_white_space done! \n",
      "\n",
      "Remove_white_space done! \n",
      "\n",
      "Remove_white_space done! \n",
      "\n",
      "Remove_white_space done! \n",
      "\n",
      "Remove_white_space done! \n",
      "\n",
      "Remove_white_space done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = RawData(input_data)\n",
    "test.remove_white_space()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mapping_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping_2563\n",
    "mapping = pd.read_excel(input_mapping+'RPISIC01_20201231_ข้อมูลรายตัวสำหรับตรวจสอบ (22 ประเภทธุรกิจ).xlsb',engine='pyxlsb',usecols=['Customer Number','Account Number','USER2','Account Class','PF/NPF Flag'] )\n",
    "#mapping_2564\n",
    "mapping2 = pd.read_excel(input_mapping+'RPISIC01_20211231_ข้อมูลรายตัวสำหรับตรวจสอบ (22 ประเภทธุรกิจ).xlsb',engine='pyxlsb',usecols=['Customer Number','Account Number','USER2','Account Class','PF/NPF Flag'] )\n",
    "#mapping_2565\n",
    "mapping3 = pd.read_excel(input_mapping+'RPISIC01_20221231_ข้อมูลรายตัวสำหรับตรวจสอบ (22 ประเภทธุรกิจ).xlsb',engine='pyxlsb',usecols=['Customer Number','Account Number','USER2','Account Class','PF/NPF Flag'] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backupdata\n",
    "def backupdata(df,year):\n",
    "      print(f\"backup data file '{year}' done!\",\"\\n\")\n",
    "      return df.to_csv(backup_data+'data'+year+'.csv',encoding='TIS-620',index=False)\n",
    "      \n",
    "      \n",
    "#define good_bad\n",
    "def define_Good_Bad(df):\n",
    "    condition = [(df['USER2'] == 'B1')|(df['USER2'] == 'B2'),(df['USER2'] == 'B2')|(df['USER2'] == 'B4')|(df['USER2'] == 'B5')]\n",
    "    mapping_Good = (1,0)\n",
    "    mapping_Bad = (0,1)\n",
    "    df['Good'] = np.select(condition, mapping_Good)\n",
    "    df['Bad'] = np.select(condition, mapping_Bad)\n",
    "    return df\n",
    "\n",
    "#validate\n",
    "def validate(df):\n",
    "  table = df[['Grade','Good','Bad']].groupby(['Grade']).sum()\n",
    "  table.reset_index(inplace=True)\n",
    "  table.sort_index(ascending=False,inplace=True)\n",
    "  table['N'] = table['Good'] + table['Bad']\n",
    "  table['badRate'] = table['Bad'] / table['N']\n",
    "  table['goodRate'] = table['Good'] / table['N']\n",
    "  table['%Bad'] = table['Bad'] / table['Bad'].sum()\n",
    "  table['%Good'] = table['Good'] / table['Good'].sum()\n",
    "  table['cumBadFreq'] = table['%Bad'].cumsum()\n",
    "  table['cumGoodFreq'] = table['%Good'].cumsum()\n",
    "  table['BGOdds'] = table['Bad'].cumsum() / table['Good'].cumsum()\n",
    "  table['GBOdds'] = table['Good'].cumsum() / table['Bad'].cumsum()\n",
    "  table['cumBad'] = table['Bad'].cumsum() / table['Bad'].sum()\n",
    "  table['cumGood'] = table['Good'].cumsum() / table['Good'].sum()\n",
    "  table['ROC'] = (table['cumGood'] - table['cumGood'].shift(1, fill_value = 0)) * \\\n",
    "                 (table['cumBad'] + table['cumBad'].shift(1, fill_value = 0)) * 0.5\n",
    "  table['KS'] = abs(table['cumGood'] - table['cumBad']) \n",
    "  print(f\"validate done!\",\"\\n\")\n",
    "  return table\n",
    "\n",
    "##Plot_KS\n",
    "def plot_KS(df):\n",
    "  year = [x for x in globals() if globals()[x] is df][0]  \n",
    "  #year = year[-4:]  \n",
    "  KS = df['KS'].max()\n",
    "  plt.figure(figsize = (10, 6))\n",
    "  plt.plot(\n",
    "    np.hstack((0, df['cumGood'])),\n",
    "    c = 'forestgreen',\n",
    "    label = 'Cumulative good'\n",
    "  )\n",
    "  plt.plot(\n",
    "    np.hstack((0, df['cumBad'])),\n",
    "    c = 'gray',\n",
    "    label = 'Cumulative bad'\n",
    "    )\n",
    "  plt.plot([], [], ' ', label = f'KS: {KS * 100:.2f}%')\n",
    "  plt.xticks(\n",
    "    np.arange(1, df.shape[0] + 1),\n",
    "    df['Grade']\n",
    "  )\n",
    "  # Fotmat axis label\n",
    "  ks_max_idx = df['KS'].idxmax()\n",
    "  ks_N_idx = df.index.max()\n",
    "\n",
    "  plt.gca().set_yticklabels([f'{y * 100:.2f}%' for y in plt.gca().get_yticks()])\n",
    "  plt.title('KS Curve_'+year)\n",
    "  plt.xlabel('Score bands')\n",
    "  plt.ylabel('Percentage of cumulative')\n",
    "  plt.legend(frameon = True, facecolor = 'white')\n",
    "  plt.vlines(ks_N_idx-ks_max_idx+1, ymin = df['cumBad'][ks_max_idx],\n",
    "             ymax = df['cumGood'][ks_max_idx], color=\"k\", linestyles=\"--\")\n",
    "  print(f\"plot Graph_KS_\"+year+\" done!\",\"\\n\")\n",
    "  #plt.close()\n",
    "  return plt.gcf()\n",
    "\n",
    "# Plot\n",
    "# ROC_GINI\n",
    "def plot_AUC_GINI(df):\n",
    "    year = [x for x in globals() if globals()[x] is df][0]  \n",
    "    AUC = df['ROC'].sum()\n",
    "    GINI = AUC*2-1\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(\n",
    "        np.hstack((0, df['cumGood'])),\n",
    "        np.hstack((0, df['cumBad'])),\n",
    "        c = 'forestgreen',\n",
    "        label = 'ROC Curve'\n",
    "    )\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        c = 'gray',\n",
    "        linestyle = '--',\n",
    "        label = 'Random curve'\n",
    "    )\n",
    "    plt.plot([], [], ' ', label = f'AUC: {AUC * 100:.2f}%, GINI: {GINI * 100:.2f}%')\n",
    "    # Fotmat axis label\n",
    "    plt.gca().set_xticklabels([f'{x * 100:.2f}%' for x in plt.gca().get_xticks()])\n",
    "    plt.gca().set_yticklabels([f'{y * 100:.2f}%' for y in plt.gca().get_yticks()])\n",
    "    plt.title('ROC Curve_'+year)\n",
    "    plt.xlabel('Percentage of good')\n",
    "    plt.ylabel('Percentage of bad')\n",
    "    plt.legend(frameon = True, facecolor = 'white')\n",
    "    print(f\"plot Graph_AUC_GINI_\"+year+\" done!\",\"\\n\")\n",
    "    #plt.close()\n",
    "    return plt.gcf()\n",
    "\n",
    "##export graph to jpg\n",
    "def export_Graph(graph):\n",
    "    fname = [x for x in globals() if globals()[x] is graph][0]  \n",
    "    graph.savefig(output_graph+fname+'.jpg') \n",
    "    print(f\"export Graph done!\",\"\\n\")\n",
    "\n",
    "### Preparedata_Grade (delete number)\n",
    "def grade_Fix(df):\n",
    "    condition = [(df['Grade'] == '1.AAA')|(df['Grade'] == 'AAA'),(df['Grade'] == '2.AA')|(df['Grade'] == 'AA'),(df['Grade'] == '3.A+')|(df['Grade'] == 'A+'),(df['Grade'] == '4.BBB')|(df['Grade'] == 'BBB'),(df['Grade'] == '5.BB')|(df['Grade'] == 'BB'),\n",
    "                 (df['Grade'] == '6.B+')|(df['Grade'] == 'B+'),(df['Grade'] == '7.CCC')|(df['Grade'] == 'CCC'),(df['Grade'] == '8.CC')|(df['Grade'] == 'CC'),(df['Grade'] == '9.C+')|(df['Grade'] == 'C+'),(df['Grade'] == '10.DDD')|(df['Grade'] == 'DDD'),\n",
    "                 (df['Grade'] == '11.DD')|(df['Grade'] == 'DD'),(df['Grade'] == '12.D+')|(df['Grade'] == 'D+'),(df['Grade'] == '13.sAAA')|(df['Grade'] == 'sAAA'),(df['Grade'] == '14.sAA')|(df['Grade'] == 'sAA'),(df['Grade'] == '15.sA+')|(df['Grade'] == 'sA+'),\n",
    "                 (df['Grade'] == '16.sBBB')|(df['Grade'] == 'sBBB'),(df['Grade'] == '17.sBB')|(df['Grade'] == 'sBB'),(df['Grade'] == '18.sB+')|(df['Grade'] == 'sB+'),(df['Grade'] == '19.sCCC')|(df['Grade'] == 'sCCC'),(df['Grade'] == '20.sCC')|(df['Grade'] == 'sCC'),\n",
    "                 (df['Grade'] == '21.sC+')|(df['Grade'] == 'sC+'),(df['Grade'] == '22.sDDD')|(df['Grade'] == 'sDDD'),(df['Grade'] == '23.sDD')|(df['Grade'] == 'sDD'),(df['Grade'] == '24.sD+')|(df['Grade'] == 'sD+')]\n",
    "    mapping_Grade = ('AAA','AA','A+','BBB','BB','B+','CCC','CC','C+','DDD','DD','D+','sAAA','sAA','sA+','sBBB','sBB','sB+','sCCC','sCC','sC+','sDDD','sDD','sD+')\n",
    "    df['Grade'] = np.select(condition, mapping_Grade)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare_data_2563 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prepare \n",
    "data = pd.read_csv(input_data+'CRR2563.csv',encoding='UTF-8')\n",
    "data['เลขที่ CIF'] = data['เลขที่ CIF'].str.strip()\n",
    "data.dropna(subset=['เลขที่ CIF'],inplace=True)\n",
    "data.rename(columns={\"เลขที่ CIF\": \"Customer Number\"},inplace=True)\n",
    "### fitter not number\n",
    "data_main = data[data['Customer Number'].str.contains(r'[0-9]')]\n",
    "### convert type object to int\n",
    "data_main['Customer Number'] = data_main['Customer Number'].astype(np.int64)\n",
    "### map data\n",
    "df = data_main.merge(mapping,on='Customer Number',how='left')\n",
    "df = df.dropna(subset=['USER2'])\n",
    "df = df.drop_duplicates(subset=['Customer Number'])\n",
    "df = df.dropna(subset=['Grade'])\n",
    "df = df[~(df['Grade']=='-')]\n",
    "df.reset_index(drop=True)\n",
    "### Define Good_Bad\n",
    "df_2563 = define_Good_Bad(df)\n",
    "### backup_data\n",
    "backupdata(df_2563,'2563')\n",
    "### Medium && Large CRR\n",
    "df_2563['Grade'].isna().value_counts()\n",
    "df_2563.groupby(['Grade']).count()\n",
    "df_CRR_2563 = df_2563[~df_2563['Grade'].str.contains('[s,S]')]\n",
    "df_CRR_2563[['Grade','Good','Bad']].groupby(['Grade']).sum()\n",
    "### Small CRR\n",
    "df_sCRR_2563 = df_2563[df_2563['Grade'].str.contains('[s,S]')]\n",
    "df_sCRR_2563.loc[df_sCRR_2563['Grade']=='SBB','Grade'] = 'sBB'\n",
    "df_sCRR_2563.loc[df_sCRR_2563['Grade']=='sc+','Grade'] = 'sC+'\n",
    "df_sCRR_2563 = df_sCRR_2563[~(df_sCRR_2563['Grade']=='SS')]\n",
    "df_sCRR_2563[['Grade','Good','Bad']].groupby(['Grade']).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare_data_2564 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backup data file '2564' done! \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Good</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sA+</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sB+</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBB</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sBBB</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sC+</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sCC</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sCCC</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sDD</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sDDD</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Good  Bad\n",
       "Grade           \n",
       "sA+      16    0\n",
       "sB+      67    0\n",
       "sBB      83    0\n",
       "sBBB     56    0\n",
       "sC+      27    1\n",
       "sCC      46    0\n",
       "sCCC     37    0\n",
       "sDD       1    1\n",
       "sDDD     12    0"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### prepare \n",
    "data = pd.read_csv(input_data+'CRR2564.csv',encoding='UTF-8')\n",
    "data['เลขที่ CIF'] = data['เลขที่ CIF'].str.strip()\n",
    "data.dropna(subset=['เลขที่ CIF'],inplace=True)\n",
    "data.rename(columns={\"เลขที่ CIF\": \"Customer Number\"},inplace=True)\n",
    "### fitter not number\n",
    "data_main = data[data['Customer Number'].str.contains(r'[0-9]')]\n",
    "data_main = data_main[data_main['Customer Number'] != 'G514300']\n",
    "### convert type object to int\n",
    "data_main['Customer Number'] = data_main['Customer Number'].astype(np.int64)\n",
    "df = data_main.merge(mapping,on='Customer Number',how='left')\n",
    "df = df.dropna(subset=['USER2'])\n",
    "df = df.drop_duplicates(subset=['Customer Number'])\n",
    "df = df.dropna(subset=['Grade'])\n",
    "df = df[~(df['Grade']=='-')]\n",
    "df.reset_index(drop=True)\n",
    "### map data\n",
    "df = data_main.merge(mapping,on='Customer Number',how='left')\n",
    "df = df.dropna(subset=['USER2'])\n",
    "df = df.drop_duplicates(subset=['Customer Number'])\n",
    "df = df.dropna(subset=['Grade'])\n",
    "df = df[~(df['Grade']=='-')]\n",
    "df.reset_index(drop=True)\n",
    "### Preparedata_Grade\n",
    "#df['Grade'].unique()\n",
    "grade_Fix(df)\n",
    "#df.groupby(['Grade']).sum()\n",
    "### Define Good_Bad\n",
    "df_2564 = define_Good_Bad(df)\n",
    "### backup_data\n",
    "backupdata(df_2564,'2564')\n",
    "### Medium && Large CRR\n",
    "df_CRR_2564 = df_2564[~df_2564['Grade'].str.contains('[s,S]')]\n",
    "df_CRR_2564[['Grade','Good','Bad']].groupby(['Grade']).sum()\n",
    "### Small CRR\n",
    "df_sCRR_2564 = df_2564[df_2564['Grade'].str.contains('[s,S]')]\n",
    "df_sCRR_2564[['Grade','Good','Bad']].groupby(['Grade']).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare_data_2565 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##As_of_2563\n",
    "##CRR\n",
    "CRR_2563 =  validate(df_CRR_2563)\n",
    "KS_CRR_2563 = plot_KS(CRR_2563)\n",
    "export_Graph(KS_CRR_2563)\n",
    "AUC_GINI_CRR_2563 = plot_AUC_GINI(CRR_2563)\n",
    "export_Graph(AUC_GINI_CRR_2563)\n",
    "##sCRR\n",
    "sCRR_2563 =  validate(df_sCRR_2563)\n",
    "KS_sCRR_2563 = plot_KS(sCRR_2563)\n",
    "export_Graph(KS_sCRR_2563)\n",
    "AUC_GINI_sCRR_2563 = plot_AUC_GINI(sCRR_2563)\n",
    "export_Graph(AUC_GINI_sCRR_2563)\n",
    "##As_of_2564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##As_of_2564\n",
    "##CRR\n",
    "CRR_2563 =  validate(df_CRR_2563)\n",
    "KS_CRR_2563 = plot_KS(CRR_2563)\n",
    "export_Graph(KS_CRR_2563)\n",
    "AUC_GINI_CRR_2563 = plot_AUC_GINI(CRR_2563)\n",
    "export_Graph(AUC_GINI_CRR_2563)\n",
    "##sCRR\n",
    "sCRR_2563 =  validate(df_sCRR_2563)\n",
    "KS_sCRR_2563 = plot_KS(sCRR_2563)\n",
    "export_Graph(KS_sCRR_2563)\n",
    "AUC_GINI_sCRR_2563 = plot_AUC_GINI(sCRR_2563)\n",
    "export_Graph(AUC_GINI_sCRR_2563)\n",
    "##As_of_2564"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
