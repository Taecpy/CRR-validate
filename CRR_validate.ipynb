{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set libraly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import zipfile\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config InlineBackend.figure_format = 'retina' #Retina display\n",
    "plt.style.use('seaborn-deep') #Plot style\n",
    "#pd.set_option('display.max_rows', 5000)\n",
    "#pd.set_option('display.max_columns', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Input\\\\\"\n",
    "input_data = \"Input\\\\data\\\\\"\n",
    "input_mapping = \"Input\\\\mapping\\\\\"\n",
    "# input_mapping_V2 = \"Input\\\\mapping_V2\\\\\"\n",
    "output = \"Output\\\\\"\n",
    "backup_data = \"Input\\\\data\\\\backup_data\\\\\"\n",
    "output_graph = \"Output\\\\graph\\\\\"\n",
    "#os.mkdir(input)\n",
    "#os.mkdir(input_mapping_V2)\n",
    "#os.mkdir(output)\n",
    "#os.mkdir(input_data)\n",
    "#os.mkdir(input_mapping)\n",
    "#os.mkdir(backup_data)\n",
    "#os.mkdir(output_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = CRR_2563.sort_index(ascending=True)\n",
    "# a = a.iloc[:,0:4]\n",
    "# a.to_csv(output+'population_CRR_2563.csv',index=False)\n",
    "# b = sCRR_2563.sort_index(ascending=True)\n",
    "# b = b.iloc[:,0:4]\n",
    "# b.to_csv(output+'population_sCRR_2563.csv',index=False)\n",
    "\n",
    "'''''2563'''''\n",
    "# ### prepare data for main\n",
    "# data = pd.read_csv(input_data+'CRR2563.csv',encoding='UTF-8')\n",
    "# data['เลขที่ CIF'] = data['เลขที่ CIF'].str.strip()\n",
    "# data.dropna(subset=['เลขที่ CIF'],inplace=True)\n",
    "# data.rename(columns={\"เลขที่ CIF\": \"CUST_ID\"},inplace=True)\n",
    "# ## fitter not number\n",
    "# data_main = data[data['CUST_ID'].str.contains(r'[0-9]')]\n",
    "# ## convert type object to int\n",
    "# data_main['CUST_ID'] = data_main['CUST_ID'].astype(np.int64)\n",
    "# data_main['วันที่ประเมิน'] = data_main['วันที่ประเมิน'].replace({'2563':'31/12/2563'})\n",
    "# replace_year(data_main,'2563','2020')\n",
    "# DATE_end_of_mouth(data_main)\n",
    "# data_main = data_main[~(data_main['Grade']=='-')]\n",
    "# '--------------------------------------------------------------------------------'\n",
    "# ### prepare for performance\n",
    "# ### read File mapping data for performance\n",
    "# zf = zipfile.ZipFile(input_mapping+'mapping_data_2563.zip') \n",
    "# mapping = pd.read_csv(zf.open('mapping_data.txt'),encoding='TIS-620',sep='\\t')\n",
    "# df = mapping.merge(data_main,on='CUST_ID',how='left')\n",
    "# df.dropna(subset=['Grade'],inplace=True)\n",
    "# df.drop_duplicates(subset=['CUST_ID', 'AS_OF_DATE'],inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)\n",
    "# df['AS_OF_DATE'].str.strip()\n",
    "# convent_date(df)\n",
    "# df = df[['CUST_ID', 'ACC_CLASS', 'NPF_FLAG',  'AS_OF_DATE', 'วันที่ประเมิน']]\n",
    "# df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "# df.sort_values(by=['CUST_ID', 'AS_OF_DATE'], inplace=True)\n",
    "# ## define label\n",
    "# df_2563 = define_Good_Bad(data_main,df)\n",
    "# backupdata(df_2563,'2563')\n",
    "# ### CRR\n",
    "# df_CRR_2563 = df_2563[~df_2563['Grade'].str.contains('[s,S]')]\n",
    "# ### Small CRR\n",
    "# df_sCRR_2563 = df_2563[df_2563['Grade'].str.contains('[s,S]')]\n",
    "# df_sCRR_2563.loc[df_sCRR_2563['Grade']=='SBB','Grade'] = 'sBB'\n",
    "# df_sCRR_2563.loc[df_sCRR_2563['Grade']=='sc+','Grade'] = 'sC+'\n",
    "# df_sCRR_2563 = df_sCRR_2563[~(df_sCRR_2563['Grade']=='SS')]\n",
    "# ### CRR\n",
    "# CRR_2563 = pd.pivot_table(df_CRR_2563, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# CRR_2563.reset_index(inplace=True)\n",
    "# CRR_2563.set_index([pd.Index([0,3,2,1,6,5,4,9,8,7])],inplace = True)\n",
    "# CRR_2563.fillna(0,inplace=True)\n",
    "# CRR_2563 =  validate(CRR_2563)\n",
    "# KS_CRR_2563 = plot_KS(CRR_2563)\n",
    "# AUC_GINI_CRR_2563 = plot_AUC_GINI(CRR_2563)\n",
    "# ### For export Graph\n",
    "# # export_Graph(KS_CRR_2563)\n",
    "# # export_Graph(AUC_GINI_CRR_2563)\n",
    "# ### Small CRR\n",
    "# sCRR_2563 = pd.pivot_table(df_sCRR_2563, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# sCRR_2563.reset_index(inplace=True)\n",
    "# sCRR_2563.set_index([pd.Index([1,0,4,3,2,7,6,5,9,8])],inplace = True)\n",
    "# sCRR_2563.fillna(0,inplace=True)\n",
    "# sCRR_2563 =  validate(sCRR_2563)\n",
    "# KS_sCRR_2563 = plot_KS(sCRR_2563)\n",
    "# AUC_GINI_sCRR_2563 = plot_AUC_GINI(sCRR_2563)\n",
    "# ### For export Graph\n",
    "# # export_Graph(KS_sCRR_2563)\n",
    "# # export_Graph(AUC_GINI_sCRR_2563)\n",
    "\n",
    " ''''2564''''\n",
    "# ### prepare \n",
    "# data = pd.read_csv(input_data+'CRR2564.csv',encoding='UTF-8')\n",
    "# data['เลขที่ CIF'] = data['เลขที่ CIF'].str.strip()\n",
    "# data.dropna(subset=['เลขที่ CIF'],inplace=True)\n",
    "# data.rename(columns={\"เลขที่ CIF\": \"CUST_ID\"},inplace=True)\n",
    "# ### fitter not number\n",
    "# data_main = data[data['CUST_ID'].str.contains(r'[0-9]')]\n",
    "# data_main = data_main[data_main['CUST_ID'] != 'G514300']\n",
    "# ### convert type object to int\n",
    "# data_main['CUST_ID'] = data_main['CUST_ID'].astype(np.int64)\n",
    "# data_main['วันที่ประเมิน'] = data_main['วันที่ประเมิน'].replace({'28/10/64':'31/10/2564'})\n",
    "# replace_year(data_main,'2564','2021')\n",
    "# DATE_end_of_mouth(data_main)\n",
    "# '--------------------------------------------------------------------------------'\n",
    "# ### prepare for performance\n",
    "# ### read File mapping data for performance\n",
    "# zf = zipfile.ZipFile(input_mapping+'mapping_data_2564.zip') \n",
    "# mapping = pd.read_csv(zf.open('mapping_data.txt'),encoding='TIS-620',sep='\\t')\n",
    "# df = mapping.merge(data_main,on='CUST_ID',how='left')\n",
    "# df.dropna(subset=['Grade'],inplace=True)\n",
    "# df.drop_duplicates(subset=['CUST_ID', 'AS_OF_DATE'],inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)\n",
    "# df['AS_OF_DATE'].str.strip()\n",
    "# convent_date(df)\n",
    "# df = df[['CUST_ID', 'ACC_CLASS', 'NPF_FLAG',  'AS_OF_DATE', 'วันที่ประเมิน']]\n",
    "# df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "# df.sort_values(by=['CUST_ID', 'AS_OF_DATE'], inplace=True)\n",
    "# ## define label\n",
    "# df_2564 = define_Good_Bad(data_main,df)\n",
    "# grade_Fix(df_2564)\n",
    "# # # ### backup_data\n",
    "# backupdata(df_2564,'2564')\n",
    "### Medium && Large CRR\n",
    "# df_CRR_2564 = df_2564[~df_2564['Grade'].str.contains('[s,S]')]\n",
    "# ### Small CRR\n",
    "# df_sCRR_2564 = df_2564[df_2564['Grade'].str.contains('[s,S]')]\n",
    "# ### CRR\n",
    "# CRR_2564 = pd.pivot_table(df_CRR_2564, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# CRR_2564.reset_index(inplace=True)\n",
    "# CRR_2564.set_index([pd.Index([0,3,2,1,6,5,4,8,7])],inplace = True)\n",
    "# CRR_2564.fillna(0,inplace=True)\n",
    "# CRR_2564 =  validate(CRR_2564)\n",
    "# KS_CRR_2564 = plot_KS(CRR_2564)\n",
    "# AUC_GINI_CRR_2564 = plot_AUC_GINI(CRR_2564)\n",
    "# ## For export Graph\n",
    "# # export_Graph(KS_CRR_2564)\n",
    "# # export_Graph(AUC_GINI_CRR_2564)\n",
    "# '---------------------------------------------------------------------------------------------------------------------------'\n",
    "# ### Small CRR\n",
    "# sCRR_2564 = pd.pivot_table(df_sCRR_2564, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# sCRR_2564.reset_index(inplace=True)\n",
    "# sCRR_2564.set_index([pd.Index([0,3,2,1,6,5,4,8,7])],inplace = True)\n",
    "# sCRR_2564.fillna(0,inplace=True)\n",
    "# sCRR_2564 =  validate(sCRR_2564)\n",
    "# KS_sCRR_2564 = plot_KS(sCRR_2564)\n",
    "# AUC_GINI_sCRR_2564 = plot_AUC_GINI(sCRR_2564)\n",
    "# ### For export Graph\n",
    "# # export_Graph(KS_sCRR_2564)\n",
    "# # export_Graph(AUC_GINI_sCRR_2564)\n",
    "\n",
    "# ### prepare \n",
    "# data = pd.read_csv(input_data+'CRR2564_V2.csv',encoding='UTF-8')\n",
    "# data['เลขที่ CIF'] = data['เลขที่ CIF'].str.strip()\n",
    "# data.dropna(subset=['เลขที่ CIF'],inplace=True)\n",
    "# data.rename(columns={\"เลขที่ CIF\": \"CUST_ID\"},inplace=True)\n",
    "# ### fitter not number\n",
    "# data_main = data[data['CUST_ID'].str.contains(r'[0-9]')]\n",
    "# data_main = data_main[data_main['CUST_ID'] != 'G514300']\n",
    "# ### convert type object to int\n",
    "# data_main['CUST_ID'] = data_main['CUST_ID'].astype(np.int64)\n",
    "# data_main['วันที่ประเมิน'] = data_main['วันที่ประเมิน'].replace({'28/10/64':'31/10/2564'})\n",
    "# replace_year(data_main,'2564','2021')\n",
    "# replace_year(data_main,'2565','2021')\n",
    "# DATE_end_of_mouth(data_main)\n",
    "# '--------------------------------------------------------------------------------'\n",
    "# ### prepare for performance\n",
    "# ### read File mapping data for performance\n",
    "# zf = zipfile.ZipFile(input_mapping+'mapping_data_2564.zip') \n",
    "# mapping = pd.read_csv(zf.open('mapping_data.txt'),encoding='TIS-620',sep='\\t')\n",
    "# df = mapping.merge(data_main,on='CUST_ID',how='left')\n",
    "# df.dropna(subset=['Grade'],inplace=True)\n",
    "# df.drop_duplicates(subset=['CUST_ID', 'AS_OF_DATE'],inplace=True)\n",
    "# df.reset_index(drop=True,inplace=True)\n",
    "# df['AS_OF_DATE'].str.strip()\n",
    "# convent_date(df)\n",
    "# df = df[['CUST_ID', 'ACC_CLASS', 'NPF_FLAG',  'AS_OF_DATE', 'วันที่ประเมิน']]\n",
    "# df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "# df.sort_values(by=['CUST_ID', 'AS_OF_DATE'], inplace=True)\n",
    "# ## define label\n",
    "# df_2564 = define_Good_Bad(data_main,df)\n",
    "# grade_Fix(df_2564)\n",
    "# # # ### backup_data\n",
    "# # backupdata(df_2564,'2564_V2')\n",
    "# c = CRR_2564_V2.sort_index(ascending=True)\n",
    "# c = c.iloc[:,0:4]\n",
    "# c.to_csv(output+'population_CRR_2564_V2.csv',index=False)\n",
    "# d = sCRR_2564_V2.sort_index(ascending=True)\n",
    "# d = d.iloc[:,0:4]\n",
    "# d.to_csv(output+'population_sCRR_2564_V2.csv',index=False)\n",
    "### Medium && Large CRR\n",
    "# df_CRR_2564_V2 = df_2564[~df_2564['Grade'].str.contains('[s,S]')]\n",
    "# ### Small CRR\n",
    "# df_sCRR_2564_V2 = df_2564[df_2564['Grade'].str.contains('[s,S]')]\n",
    "# ### CRR\n",
    "# CRR_2564_V2 = pd.pivot_table(df_CRR_2564_V2, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# CRR_2564_V2.reset_index(inplace=True)\n",
    "# CRR_2564_V2.set_index([pd.Index([0,3,2,1,6,5,4,8,7])],inplace = True)\n",
    "# CRR_2564_V2.fillna(0,inplace=True)\n",
    "# CRR_2564_V2 =  validate(CRR_2564_V2)\n",
    "# KS_CRR_2564_V2 = plot_KS(CRR_2564_V2)\n",
    "# AUC_GINI_CRR_2564_V2 = plot_AUC_GINI(CRR_2564_V2)\n",
    "# ## For export Graph\n",
    "# # export_Graph(KS_CRR_2564_V2)\n",
    "# # export_Graph(AUC_GINI_CRR_2564_V2)\n",
    "# '---------------------------------------------------------------------------------------------------------------------------'\n",
    "# ### Small CRR\n",
    "# sCRR_2564_V2 = pd.pivot_table(df_sCRR_2564_V2, values='CUST_ID', index=['Grade'],columns=['FlagGB'], aggfunc='count')\n",
    "# sCRR_2564_V2.reset_index(inplace=True)\n",
    "# sCRR_2564_V2.set_index([pd.Index([1,0,4,3,2,7,6,5,9,8])],inplace = True)\n",
    "# sCRR_2564_V2.fillna(0,inplace=True)\n",
    "# sCRR_2564_V2 =  validate(sCRR_2564_V2)\n",
    "# KS_sCRR_2564_V2 = plot_KS(sCRR_2564_V2)\n",
    "# AUC_GINI_sCRR_2564_V2 = plot_AUC_GINI(sCRR_2564_V2)\n",
    "# ### For export Graph\n",
    "# # export_Graph(KS_sCRR_2564_V2)\n",
    "# # export_Graph(AUC_GINI_sCRR_2564_V2)\n",
    "\n",
    "''''PSI'''\n",
    "'''PSI < 0.1: No major change, you can continue with the current model. <(10%)\n",
    "   PSI < 0.2: Moderate population change, use your best judgement. <(20%)\n",
    "   PSI >= 0.2: Significant population change, model retraining may be required. >=(20%)'''\n",
    "# #'AAA','AA','A+','BBB','BB','B+','CCC','CC','C+','DDD','DD','D+','sAAA','sAA','sA+','sBBB','sBB','sB+','sCCC','sCC','sC+','sDDD','sDD','sD+'\n",
    "# d_C = {'Grade': ['AAA','AA','A+','BBB','BB','B+','CCC','CC','C+','DDD','DD','D+']}\n",
    "# d_SC = {'Grade': ['sAAA','sAA','sA+','sBBB','sBB','sB+','sCCC','sCC','sC+','sDDD','sDD','sD+']}\n",
    "# d_C = pd.DataFrame(data=d_C)\n",
    "# d_SC = pd.DataFrame(data=d_SC)\n",
    "# CRR_2563 = d_C.merge(CRR_2563, how='left', on='Grade')\n",
    "# CRR_2563.sort_index(ascending=False,inplace = True)\n",
    "# CRR_2564 = d_C.merge(CRR_2564_V2, how='left', on='Grade')\n",
    "# CRR_2564.sort_index(ascending=False,inplace = True)\n",
    "# sCRR_2563 = d_SC.merge(sCRR_2563, how='left', on='Grade')\n",
    "# sCRR_2563.sort_index(ascending=False,inplace = True)\n",
    "# sCRR_2564 = d_SC.merge(sCRR_2564_V2, how='left', on='Grade')\n",
    "# sCRR_2564.sort_index(ascending=False,inplace = True)\n",
    "# # PSI(CRR_2564,CRR_2563)\n",
    "# PSI_CRR_2564 = plot_PSI(CRR_2564,CRR_2563)\n",
    "# # PSI(sCRR_2564,sCRR_2563)\n",
    "# PSI_sCRR_2564 = plot_PSI(sCRR_2564,sCRR_2563)\n",
    "# export_Graph(PSI_CRR_2564)\n",
    "# export_Graph(PSI_sCRR_2564)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input last data and preliminary clean data\n",
    "def load_input():\n",
    "    filename = glob.glob(os.path.join(input_data,'*.csv'))[-1]\n",
    "    df = pd.read_csv(filename,encoding='TIS-620')\n",
    "    df.dropna(subset=['CUST_ID'],inplace=True)\n",
    "    df = df[~df['CUST_ID'].str.contains(r'[A-Z]')]\n",
    "    df = df[~df['CUST_ID'].str.contains(r'[-]')]\n",
    "    df['CUST_ID'] = df['CUST_ID'].astype('int64')\n",
    "    df.reset_index(drop=True,inplace = True)\n",
    "    df['วันที่ประเมิน'] = pd.to_datetime(df['วันที่ประเมิน'])\n",
    "    df['วันที่ประเมิน'] = df['วันที่ประเมิน'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return df\n",
    "\n",
    "def load_performance():\n",
    "    filename = glob.glob(os.path.join(input_mapping,'*.csv'))[-1]\n",
    "    df = pd.read_csv(filename,encoding='TIS-620',sep=',')\n",
    "    df['AS_OF_DATE'] = pd.to_datetime(df['AS_OF_DATE'])\n",
    "    df['AS_OF_DATE'] = df['AS_OF_DATE'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return df\n",
    "\n",
    "\n",
    "# def split_data(df):\n",
    "#     df\n",
    "\n",
    "#backupdata\n",
    "def backupdata(df,year):\n",
    "      print(f\"backup data file '{year}' done!\",\"\\n\")\n",
    "      return df.to_csv(backup_data+'data'+year+'.csv',encoding='TIS-620',index=False)\n",
    "\n",
    "#replace year พ.ศ - ค.ศ     \n",
    "def replace_year(df,year,year_n):\n",
    "    #data.iloc[:,6] = data.iloc[:,6].astype(str)\n",
    "    df.iloc[:,2] = df.iloc[:,2].str.replace(year,year_n)\n",
    "    return df\n",
    "\n",
    "# get end of date month\n",
    "def DATE_end_of_mouth(df):\n",
    "    df.iloc[:,2] = pd.to_datetime(df.iloc[:,2], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "    df.iloc[:,2] = pd.to_datetime(df.iloc[:,2]) + MonthEnd(0)\n",
    "    return df\n",
    "\n",
    "def convent_date(df):\n",
    "    condition = [(df['AS_OF_DATE'] == '31 ม.ค.  2020'),(df['AS_OF_DATE'] == '29 ก.พ.  2020'),(df['AS_OF_DATE'] == '31 มี.ค. 2020'),(df['AS_OF_DATE'] == '30 เม.ย. 2020'),(df['AS_OF_DATE'] == '31 พ.ค.  2020'),\n",
    "                 (df['AS_OF_DATE'] == '30 มิ.ย. 2020'),(df['AS_OF_DATE'] == '31 ก.ค.  2020'),(df['AS_OF_DATE'] == '31 ส.ค.  2020'),(df['AS_OF_DATE'] == '30 ก.ย.  2020'),(df['AS_OF_DATE'] == '31 ต.ค.  2020'),\n",
    "                 (df['AS_OF_DATE'] == '30 พ.ย.  2020'),(df['AS_OF_DATE'] == '31 ธ.ค.  2020'),\n",
    "                 (df['AS_OF_DATE'] == '31 ม.ค.  2021'),(df['AS_OF_DATE'] == '28 ก.พ.  2021'),(df['AS_OF_DATE'] == '31 มี.ค. 2021'),(df['AS_OF_DATE'] == '30 เม.ย. 2021'),(df['AS_OF_DATE'] == '31 พ.ค.  2021'),\n",
    "                 (df['AS_OF_DATE'] == '30 มิ.ย. 2021'),(df['AS_OF_DATE'] == '31 ก.ค.  2021'),(df['AS_OF_DATE'] == '31 ส.ค.  2021'),(df['AS_OF_DATE'] == '30 ก.ย.  2021'),(df['AS_OF_DATE'] == '31 ต.ค.  2021'),\n",
    "                 (df['AS_OF_DATE'] == '30 พ.ย.  2021'),(df['AS_OF_DATE'] == '31 ธ.ค.  2021'),\n",
    "                 (df['AS_OF_DATE'] == '31 ม.ค.  2022'),(df['AS_OF_DATE'] == '28 ก.พ.  2022'),(df['AS_OF_DATE'] == '31 มี.ค. 2022'),(df['AS_OF_DATE'] == '30 เม.ย. 2022'),(df['AS_OF_DATE'] == '31 พ.ค.  2022'),\n",
    "                 (df['AS_OF_DATE'] == '30 มิ.ย. 2022'),(df['AS_OF_DATE'] == '31 ก.ค.  2022'),(df['AS_OF_DATE'] == '31 ส.ค.  2022'),(df['AS_OF_DATE'] == '30 ก.ย.  2022'),(df['AS_OF_DATE'] == '31 ต.ค.  2022'),\n",
    "                 (df['AS_OF_DATE'] == '30 พ.ย.  2022'),(df['AS_OF_DATE'] == '31 ธ.ค.  2022')]\n",
    "    mapping_date = ('2020-01-31','2020-02-29','2020-03-31','2020-04-30','2020-05-31','2020-06-30','2020-07-31','2020-08-31','2020-09-30','2020-10-31','2020-11-30','2020-12-31',\n",
    "                    '2021-01-31','2021-02-28','2021-03-31','2021-04-30','2021-05-31','2021-06-30','2021-07-31','2021-08-31','2021-09-30','2021-10-31','2021-11-30','2021-12-31',\n",
    "                    '2022-01-31','2022-02-28','2022-03-31','2022-04-30','2022-05-31','2022-06-30','2022-07-31','2022-08-31','2022-09-30','2022-10-31','2022-11-30','2022-12-31')\n",
    "    df['AS_OF_DATE'] = np.select(condition, mapping_date)\n",
    "    return df\n",
    "\n",
    "#define good_bad\n",
    "def define_Good_Bad(df_main,df):\n",
    " # create empty list for concat DataFrame\n",
    "    df_list = []\n",
    "    # get unique value for Map\n",
    "    # cust_id = df['CUST_ID'].unique()[1:2]\n",
    "    cust_id = df_main['CUST_ID'].unique()\n",
    "\n",
    "    \"\"\" Loop procress for create 12 months window performance default\"\"\"\n",
    "    for i in cust_id:\n",
    "        # map each CID\n",
    "        df_i = df[df['CUST_ID'].isin([i])]\n",
    "        df_i2 = df_main[df_main['CUST_ID'].isin([i])]\n",
    "        # select start date for window performance\n",
    "        df_i = df_i[df_i['AS_OF_DATE'] >= df_i2['วันที่ประเมิน'].unique()[0]]\n",
    "\n",
    "        # create field 'Performance' by \"AS_OF_DATE\" minus \"Review_Date\"\n",
    "        df_i['Performance'] = df_i['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_i2['วันที่ประเมิน'].dt.to_period('M').astype('int64')\n",
    "        \n",
    "        # cut tail, not exceed 12 months\n",
    "        df_i = df_i[df_i['Performance'] <= 12] \n",
    "        # fill NA\n",
    "        df_i.fillna({'NPF_FLAG':'N'}, inplace=True)\n",
    "\n",
    "        # create field 'FlagDef' for groupby\n",
    "        df_i['FlagDef'] = df_i['NPF_FLAG'].apply(lambda x: 0 if x == 'N' else 1)\n",
    "\n",
    "        # append to list\n",
    "        df_list.append(df_i)\n",
    "    df_list = pd.concat(df_list)\n",
    "    # df_list = df_list.groupby('CUST_ID')[['FlagDef']].sum()\n",
    "    # df_list['FlagGB'] = df_list['FlagDef'].apply(lambda x : 'Good' if x == 0 else 'Bad')\n",
    "    # data_main = df_main.merge(df_list,how='left',on='CUST_ID')\n",
    "    # data_main.dropna(subset=['FlagGB'],inplace=True)\n",
    "    return df_list\n",
    "\n",
    "\n",
    "#validate\n",
    "def validate(df):\n",
    "  # table = df[['Grade','Good','Bad']].groupby(['Grade']).sum()\n",
    "  # table.reset_index(inplace=True)\n",
    "  table = df\n",
    "  table.sort_index(ascending=False,inplace=True)\n",
    "  table['N'] = table['Good'] + table['Bad']\n",
    "  table['badRate'] = table['Bad'] / table['N']\n",
    "  table['goodRate'] = table['Good'] / table['N']\n",
    "  table['%Bad'] = table['Bad'] / table['Bad'].sum()\n",
    "  table['%Good'] = table['Good'] / table['Good'].sum()\n",
    "  table['cumBadFreq'] = table['%Bad'].cumsum()\n",
    "  table['cumGoodFreq'] = table['%Good'].cumsum()\n",
    "  table['BGOdds'] = table['Bad'].cumsum() / table['Good'].cumsum()\n",
    "  table['GBOdds'] = table['Good'].cumsum() / table['Bad'].cumsum()\n",
    "  table['cumBad'] = table['Bad'].cumsum() / table['Bad'].sum()\n",
    "  table['cumGood'] = table['Good'].cumsum() / table['Good'].sum()\n",
    "  table['ROC'] = (table['cumGood'] - table['cumGood'].shift(1, fill_value = 0)) *\\\n",
    "                 (table['cumBad'] + table['cumBad'].shift(1, fill_value = 0)) * 0.5\n",
    "  table['KS'] = abs(table['cumGood'] - table['cumBad']) \n",
    "  print(f\"validate done!\",\"\\n\")\n",
    "  return table\n",
    "\n",
    "# PSI\n",
    "# Define function model stability (PSI)\n",
    "def PSI(df1, df2):\n",
    "  valTime = df1['N'] / df1['N'].sum()\n",
    "  inTime = df2['N'] / df2['N'].sum()\n",
    "  result = (valTime - inTime) * np.log(\n",
    "      valTime / inTime\n",
    "  )\n",
    "  return np.sum(result)\n",
    "\n",
    "\n",
    "##Plot_KS\n",
    "def plot_KS(df):\n",
    "  year = [x for x in globals() if globals()[x] is df][0]  \n",
    "  #year = year[-4:]  \n",
    "  KS = df['KS'].max()\n",
    "  plt.figure(figsize = (10, 6))\n",
    "  plt.plot(\n",
    "    np.hstack((0, df['cumGood'])),\n",
    "    c = 'forestgreen',\n",
    "    label = 'Cumulative good'\n",
    "  )\n",
    "  plt.plot(\n",
    "    np.hstack((0, df['cumBad'])),\n",
    "    c = 'gray',\n",
    "    label = 'Cumulative bad'\n",
    "    )\n",
    "  plt.plot([], [], ' ', label = f'KS: {KS * 100:.2f}%')\n",
    "  plt.xticks(\n",
    "    np.arange(1, df.shape[0] + 1),\n",
    "    df['Grade']\n",
    "  )\n",
    "  # Fotmat axis label\n",
    "  ks_max_idx = df['KS'].idxmax()\n",
    "  ks_N_idx = df.index.max()\n",
    "\n",
    "  plt.gca().set_yticklabels([f'{y * 100:.2f}%' for y in plt.gca().get_yticks()])\n",
    "  plt.title('KS Curve_'+year)\n",
    "  plt.xlabel('Score bands')\n",
    "  plt.ylabel('Percentage of cumulative')\n",
    "  plt.legend(frameon = True, facecolor = 'white')\n",
    "  plt.vlines(ks_N_idx-ks_max_idx+1, ymin = df['cumBad'][ks_max_idx],\n",
    "             ymax = df['cumGood'][ks_max_idx], color=\"k\", linestyles=\"--\")\n",
    "  print(f\"plot Graph_KS_\"+year+\" done!\",\"\\n\")\n",
    "  #plt.close()\n",
    "  return plt.gcf()\n",
    "\n",
    "\n",
    "# Plot\n",
    "# ROC_GINI\n",
    "def plot_AUC_GINI(df):\n",
    "    year = [x for x in globals() if globals()[x] is df][0]  \n",
    "    AUC = df['ROC'].sum()\n",
    "    GINI = AUC*2-1\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.plot(\n",
    "        np.hstack((0, df['cumGood'])),\n",
    "        np.hstack((0, df['cumBad'])),\n",
    "        c = 'forestgreen',\n",
    "        label = 'ROC Curve'\n",
    "    )\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        c = 'gray',\n",
    "        linestyle = '--',\n",
    "        label = 'Random curve'\n",
    "    )\n",
    "    plt.plot([], [], ' ', label = f'AUC: {AUC * 100:.2f}%, GINI: {GINI * 100:.2f}%')\n",
    "    # Fotmat axis label\n",
    "    plt.gca().set_xticklabels([f'{x * 100:.2f}%' for x in plt.gca().get_xticks()])\n",
    "    plt.gca().set_yticklabels([f'{y * 100:.2f}%' for y in plt.gca().get_yticks()])\n",
    "    plt.title('ROC Curve_'+year)\n",
    "    plt.xlabel('Percentage of good')\n",
    "    plt.ylabel('Percentage of bad')\n",
    "    plt.legend(frameon = True, facecolor = 'white')\n",
    "    print(f\"plot Graph_AUC_GINI_\"+year+\" done!\",\"\\n\")\n",
    "    #plt.close()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Plot\n",
    "# PSI\n",
    "def plot_PSI(scoreVal,scoreDev):\n",
    "    year = [x for x in globals() if globals()[x] is scoreVal][0] \n",
    "    PSIResult = PSI(scoreVal, scoreDev)\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    plt.title('Score bands distributions comparison_'+year)\n",
    "    plt.xlabel('Score bands')\n",
    "    plt.ylabel('Percentage of accounts')\n",
    "    plt.bar(\n",
    "        np.arange(scoreDev.shape[0]) - 0.4 / 2,\n",
    "        scoreDev['N'] / scoreVal['N'].sum(),\n",
    "        0.4,\n",
    "        color = 'forestgreen',\n",
    "        label = 'Development'\n",
    "    )\n",
    "    plt.bar(\n",
    "        np.arange(scoreVal.shape[0]) + 0.4 / 2,\n",
    "        scoreVal['N'] / scoreVal['N'].sum(),\n",
    "        0.4,\n",
    "        color = 'darkblue',\n",
    "        label = 'Validation'\n",
    "    )\n",
    "    plt.plot([], [], ' ', label = f'PSI: {PSIResult * 100:.2f}%')\n",
    "    # Fotmat axis label\n",
    "    plt.gca().set_yticklabels([f'{y * 100:.2f}%' for y in plt.gca().get_yticks()])\n",
    "    plt.xticks(\n",
    "        np.arange(scoreDev.shape[0]),\n",
    "        scoreDev['Grade']\n",
    "    )\n",
    "    plt.legend(frameon = True, facecolor = 'white')\n",
    "    # plt.show()\n",
    "    print(f\"PSI_\"+year+\" done!\",\"\\n\")\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "##export graph to jpg\n",
    "def export_Graph(graph):\n",
    "    fname = [x for x in globals() if globals()[x] is graph][0]  \n",
    "    graph.savefig(output_graph+fname+'.jpg') \n",
    "    print(f\"export Graph done!\",\"\\n\")\n",
    "\n",
    "### Preparedata_Grade (delete number)\n",
    "def grade_Fix(df):\n",
    "    condition = [(df['Grade'] == '1.AAA')|(df['Grade'] == 'AAA'),(df['Grade'] == '2.AA')|(df['Grade'] == 'AA'),(df['Grade'] == '3.A+')|(df['Grade'] == 'A+'),(df['Grade'] == '4.BBB')|(df['Grade'] == 'BBB'),(df['Grade'] == '5.BB')|(df['Grade'] == 'BB'),\n",
    "                 (df['Grade'] == '6.B+')|(df['Grade'] == 'B+'),(df['Grade'] == '7.CCC')|(df['Grade'] == 'CCC'),(df['Grade'] == '8.CC')|(df['Grade'] == 'CC'),(df['Grade'] == '9.C+')|(df['Grade'] == 'C+'),(df['Grade'] == '10.DDD')|(df['Grade'] == 'DDD'),\n",
    "                 (df['Grade'] == '11.DD')|(df['Grade'] == 'DD'),(df['Grade'] == '12.D+')|(df['Grade'] == 'D+'),(df['Grade'] == '13.sAAA')|(df['Grade'] == 'sAAA'),(df['Grade'] == '14.sAA')|(df['Grade'] == 'sAA'),(df['Grade'] == '15.sA+')|(df['Grade'] == 'sA+'),\n",
    "                 (df['Grade'] == '16.sBBB')|(df['Grade'] == 'sBBB'),(df['Grade'] == '17.sBB')|(df['Grade'] == 'sBB'),(df['Grade'] == '18.sB+')|(df['Grade'] == 'sB+'),(df['Grade'] == '19.sCCC')|(df['Grade'] == 'sCCC'),(df['Grade'] == '20.sCC')|(df['Grade'] == 'sCC'),\n",
    "                 (df['Grade'] == '21.sC+')|(df['Grade'] == 'sC+'),(df['Grade'] == '22.sDDD')|(df['Grade'] == 'sDDD'),(df['Grade'] == '23.sDD')|(df['Grade'] == 'sDD'),(df['Grade'] == '24.sD+')|(df['Grade'] == 'sD+')]\n",
    "    mapping_Grade = ('AAA','AA','A+','BBB','BB','B+','CCC','CC','C+','DDD','DD','D+','sAAA','sAA','sA+','sBBB','sBB','sB+','sCCC','sCC','sC+','sDDD','sDD','sD+')\n",
    "    df['Grade'] = np.select(condition, mapping_Grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = load_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''เเก้จำนวน data ของ CRR ต้องเป็น 1-1 ต้องลบ dup key'''\n",
    "\n",
    "df_list = []\n",
    "df_list2 = []\n",
    "    # get unique value for Map\n",
    "    # cust_id = df['CUST_ID'].unique()[1:2]\n",
    "# cust_id = df['CUST_ID'].unique()\n",
    "cust_id = [750798220]\n",
    "\"\"\" Loop procress for create 12 months window performance default\"\"\"\n",
    "for i in cust_id:\n",
    "        # map each CID\n",
    "    df_i = df_p[df_p['CUST_ID'].isin([i])]\n",
    "    df_i2 = df[df['CUST_ID'].isin([i])]\n",
    "    #     # select start date for window performance\n",
    "   \n",
    "    df_i = df_i[df_i['AS_OF_DATE'] >= df_i2['วันที่ประเมิน'].unique()[0]]\n",
    "    # #     # create field 'Performance' by \"AS_OF_DATE\" minus \"Review_Date\"\n",
    "    # df_i['Performance'] = df_i['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_i2['วันที่ประเมิน'].dt.to_period('M').astype('int64')\n",
    "        \n",
    "    #     # cut tail, not exceed 12 months\n",
    "    # df_i = df_i[df_i['Performance'] <= 12] \n",
    "    #     # fill NA\n",
    "    # df_i.fillna({'NPF_FLAG':'N'}, inplace=True)\n",
    "\n",
    "    #     # create field 'FlagDef' for groupby\n",
    "    # df_i['FlagDef'] = df_i['NPF_FLAG'].apply(lambda x: 0 if x == 'N' else 1)\n",
    "\n",
    "    #     # append to list\n",
    "    df_list.append(df_i)\n",
    "\n",
    "df_list = pd.concat(df_list)\n",
    "\n",
    "    # df_list = df_list.groupby('CUST_ID')[['FlagDef']].sum()\n",
    "    # df_list['FlagGB'] = df_list['FlagDef'].apply(lambda x : 'Good' if x == 0 else 'Bad')\n",
    "    # data_main = df_main.merge(df_list,how='left',on='CUST_ID')\n",
    "    # data_main.dropna(subset=['FlagGB'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_i = df_i[df_i['AS_OF_DATE'] >= df_i2['วันที่ประเมิน'].unique()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-367-2e3d3839407a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Performance'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AS_OF_DATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf_i2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'วันที่ประเมิน'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5133\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5134\u001b[0m         ):\n\u001b[1;32m-> 5135\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\630039\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mPeriodProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "df_i['Performance'] = df_i['AS_OF_DATE'].dt.to_period('M').astype('int64') - df_i2['วันที่ประเมิน'].dt.to_period('M').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = load_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_ID</th>\n",
       "      <th>PROD_TYPE</th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BRANCH_CODE</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>LEDGER_BALANCE</th>\n",
       "      <th>ACC_CLASS</th>\n",
       "      <th>ISIC_NEW_FINAL_BY_OIS</th>\n",
       "      <th>ISIC_GROUP_NEW_BY_OIS</th>\n",
       "      <th>ACC_OPEN_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>ISIC_13GROUP</th>\n",
       "      <th>ISIC_5GROUP</th>\n",
       "      <th>NEW_SIZE_FLAG</th>\n",
       "      <th>PROF_DIV_RATE</th>\n",
       "      <th>RESTRUCTURE_FLAG</th>\n",
       "      <th>LOAN_PAYMENT_HOLIDAY</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>AS_OF_DATE</th>\n",
       "      <th>Performance</th>\n",
       "      <th>FlagDef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ACC_ID, PROD_TYPE, CUST_ID, BRANCH_CODE, CREDIT_LIMIT, LEDGER_BALANCE, ACC_CLASS, ISIC_NEW_FINAL_BY_OIS, ISIC_GROUP_NEW_BY_OIS, ACC_OPEN_DATE, ACC_OPEN_DATE_FOR_OD, MAIN_ACC_LINK, TDR_TIMES, SIZE_FLAG, NPF_LEGACY, FIRST_NPF_START_DATE, BRANCH_PROVINCE, DIVISION, LATE_CHARGE_DUE, COLLATERAL_REQUIRED, TERM_LOAN, BILL_OLDEST_DATE, NO_OF_DPD, COMMER_COMMIT_LINK1, CCL_OPENED_DATE, CCL_CREDIT_LIMIT, NPF_FLAG, YEAR_CONTRACT, SUB_TYPE, MARKET_CODE, DEALER_CODE, ISIC_NEW_FINAL, ISIC_13GROUP, ISIC_5GROUP, NEW_SIZE_FLAG, PROF_DIV_RATE, RESTRUCTURE_FLAG, LOAN_PAYMENT_HOLIDAY, DATA_SOURCE, AS_OF_DATE, Performance, FlagDef]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 42 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define_Good_Bad(df,df_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
